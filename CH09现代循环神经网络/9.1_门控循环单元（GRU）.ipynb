{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    " 我们讨论了如何在循环神经网络中计算梯度， 以及矩阵连续乘积可以导致梯度消失或梯度爆炸的问题。 下面我们简单思考一下这种梯度异常在实践中的意义：\n",
    "\n",
    "我们可能会遇到这样的情况：早期观测值对预测所有未来观测值具有非常重要的意义。 考虑一个极端情况，其中第一个观测值包含一个校验和， 目标是在序列的末尾辨别校验和是否正确。 在这种情况下，第一个词元的影响至关重要。 我们希望有某些机制能够在一个记忆元里存储重要的早期信息。 如果没有这样的机制，我们将不得不给这个观测值指定一个非常大的梯度， 因为它会影响所有后续的观测值。\n",
    "\n",
    "我们可能会遇到这样的情况：一些词元没有相关的观测值。 例如，在对网页内容进行情感分析时， 可能有一些辅助HTML代码与网页传达的情绪无关。 我们希望有一些机制来跳过隐状态表示中的此类词元。\n",
    "\n",
    "我们可能会遇到这样的情况：序列的各个部分之间存在逻辑中断。 例如，书的章节之间可能会有过渡存在， 或者证券的熊市和牛市之间可能会有过渡存在。 在这种情况下，最好有一种方法来重置我们的内部状态表示。"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 9.1.1. 门控隐状态\n",
    "门控循环单元与普通的RNN的之间的关键区别在于：\n",
    "+ RNN支持隐状态的门控\n",
    "这意味着模型有专门的机制来确定应该何时更新隐状态，以及应该何时重置隐状态。 这些机制是可学习的，并且能够解决了上面列出的问题。 例如，如果第一个词元非常重要， 模型将学会在第一次观测之后不更新隐状态。 同样，模型也可以学会跳过不相关的临时观测。 最后，模型还将学会在需要的时候重置隐状态。 下面我们将详细讨论各类门控。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 9.1.1.1. 重置门和更新门\n",
    "我们首先介绍重置门reset gate和更新门update gate。\n",
    "我们把它设计成(0, 1)区间的向量，这样我们可以进行凸组合。\n",
    "重置门允许我们控制“可能还想记住”的过去状态的数量；\n",
    "更新门允许我们控制新状态中有多少个是旧状态的副本。\n",
    "\n",
    "下图描述了GRU中的重置门和更新门的输入，\n",
    "输入是由当前时间步的输入和前一时间步的隐状态给出。\n",
    "两个门的输出是由使用sigmoid激活函数的两个全连接层给出。\n",
    "![](imgs/9_1_1_1重置门和更新门1.png)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![门控循环单元的数学表达](imgs/9_1_1_1重置门和更新门2.png)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 9.1.1.2. 候选隐状态\n",
    "接下来，把重置门$R_t$与常规隐状态更新机制集成，得到\n",
    "在时间步t的候选隐状态candidate hidden state。$\\~H_t ∈ R^{n*h}$\n",
    "$$\\~H_t = tanh(X_tW_{xh} + (R_t ⊙ H_{t-1}) W_{hh} + b_h)$$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "其中，$W_{xh}∈R^{d*h}$，$W_{hh}∈R^{h×h}$ 是权重参数， $b_h∈R^{1×h}$是偏置项，符号 ⊙ 是Hadamard积（按元素乘积）运算符。 在这里，我们使用tanh非线性激活函数来确保候选隐状态中的值保持在区间 (−1,1) 中。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "$R_t和H_{t-1}$的元素相乘可以减少以往状态的影响，\n",
    "每当重置门$R_t$中的项接近于1时，我们回复一个普通的RNN。\n",
    "对于重置门$R_t$中接近0的项，候选隐状态是以 Xt 作为输入的多层感知机的结果。 因此，任何预先存在的隐状态都会被重置为默认值。\n",
    "![在门控循环单元模型中计算候选隐状](imgs/9_1_1_2_候选隐状态1.png)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 9.1.1.3. 隐状态\n",
    "上述的计算结果只是候选隐状态，我们仍需要结合更新门$Z_t$的效果。\n",
    "这一步确定的隐状态$H_t∈R^{n*h}$在多大程度上来\n",
    "##### 来自于旧的状态$H_{t-1}$和新的候选状态$\\~H_t$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "更新门 $Z_t$ 仅需要在  $H_{t−1}$ 和 $\\~H_t$  之间进行按元素的凸组合就可以实现这个目标。 这就得出了门控循环单元的最终更新公式："
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "$$H_t = Z_t ⊙ H_{t-1} + (1-Z_t)⊙\\~H_t$$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "每当更新门 $Z_t$ 接近 1 时，模型就倾向只保留旧状态。 此时，来自\n",
    "$X_t$ 的信息基本上被忽略， 从而有效地跳过了依赖链条中的时间步 t 。 相反，当 $Z_t$ 接近 0 时， 新的隐状态 $H_t$ 就会接近候选隐状态\n",
    "$\\~H_t$ 。 这些设计可以帮助我们处理循环神经网络中的梯度消失问题， 并更好地捕获时间步距离很长的序列的依赖关系。 例如，如果整个子序列的所有时间步的更新门都接近于 1 ， 则无论序列的长度如何，在序列起始时间步的旧隐状态都将很容易保留并传递到序列结束。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![计算门控循环单元模型中的隐状态](imgs/9_1_1_3隐状态1.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 9.1.2. 从零开始实现"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "\n",
    "batch_size, num_steps = 32, 35\n",
    "train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 9.1.2.1. 初始化模型参数\n",
    "下一步是初始化模型参数。 我们从标准差为 0.01 的高斯分布中提取权重， 并将偏置项设为 0 ，超参数num_hiddens定义隐藏单元的数量， 实例化与更新门、重置门、候选隐状态和输出层相关的所有权重和偏置。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def get_params(vocab_size, num_hiddens, device):\n",
    "    num_inputs = num_outputs = vocab_size\n",
    "    def normal(shape):\n",
    "        return torch.randn(size=shape, device=device)*0.01\n",
    "    def three():\n",
    "        return (normal((num_inputs, num_hiddens)),\n",
    "                normal((num_hiddens, num_hiddens)),\n",
    "                torch.zeros(num_hiddens, device=device))\n",
    "    W_xz, W_hz, b_z = three()  # 更新门参数\n",
    "    W_xr, W_hr, b_r = three()  # 重置门参数\n",
    "    W_xh, W_hh, b_h = three()  # 候选隐状态参数\n",
    "    # 输出层参数\n",
    "    W_hq = normal((num_hiddens, num_outputs))\n",
    "    b_q = torch.zeros(num_outputs, device=device)\n",
    "    # 附加梯度\n",
    "    params = [W_xz, W_hz, b_z, W_xr, W_hr, b_r, W_xh, W_hh, b_h, W_hq, b_q]\n",
    "    for param in params:\n",
    "        param.requires_grad_(True)\n",
    "    return params"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 9.1.2.2. 定义模型\n",
    "现在我们将定义隐状态的初始化函数init_gru_state。 与 8.5节中定义的init_rnn_state函数一样， 此函数返回一个形状为（批量大小，隐藏单元个数）的张量，张量的值全部为零。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def init_gru_state(batch_size, num_hiddens, device):\n",
    "    return (torch.zeros((batch_size, num_hiddens), device=device), )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def gru(inputs, state, params):\n",
    "    W_xz, W_hz, b_z, W_xr, W_hr, b_r, W_xh, W_hh, b_h, W_hq, b_q = params\n",
    "    H, = state\n",
    "    outputs = []\n",
    "    for X in inputs:\n",
    "        Z = torch.sigmoid((X @ W_xz) + (H @ W_hz) + b_z)\n",
    "        R = torch.sigmoid((X @ W_xr) + (H @ W_hr) + b_r)\n",
    "        H_tilda = torch.tanh((X @ W_xh) + ((R * H) @ W_hh) + b_h)\n",
    "        H = Z * H + (1 - Z) * H_tilda\n",
    "        Y = H @ W_hq + b_q\n",
    "        outputs.append(Y)\n",
    "    return torch.cat(outputs, dim=0), (H,)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 9.1.2.3. 训练与预测\n",
    "训练和预测的工作方式与 8.5节完全相同。 训练结束后，我们分别打印输出训练集的困惑度， 以及前缀“time traveler”和“traveler”的预测序列上的困惑度。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_18376/2408885005.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[0mvocab_size\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnum_hiddens\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdevice\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvocab\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m256\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0md2l\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtry_gpu\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0mnum_epochs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlr\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m500\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m model = d2l.RNNModelScratch(len(vocab), num_hiddens, device, get_params,\n\u001B[0m\u001B[0;32m      4\u001B[0m                             init_gru_state, gru)\n\u001B[0;32m      5\u001B[0m \u001B[0md2l\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain_ch8\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrain_iter\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvocab\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlr\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnum_epochs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'cpu'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\d2l\\torch.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, vocab_size, num_hiddens, device, get_params, init_state, forward_fn)\u001B[0m\n\u001B[0;32m    722\u001B[0m         \u001B[1;34m\"\"\"Defined in :numref:`sec_rnn_scratch`\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    723\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvocab_size\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnum_hiddens\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mvocab_size\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnum_hiddens\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 724\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mparams\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mget_params\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvocab_size\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnum_hiddens\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    725\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0minit_state\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mforward_fn\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0minit_state\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mforward_fn\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    726\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_18376/3769477392.py\u001B[0m in \u001B[0;36mget_params\u001B[1;34m(vocab_size, num_hiddens, device)\u001B[0m\n\u001B[0;32m      7\u001B[0m                 \u001B[0mnormal\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnum_hiddens\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnum_hiddens\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      8\u001B[0m                 torch.zeros(num_hiddens, device=device))\n\u001B[1;32m----> 9\u001B[1;33m     \u001B[0mW_xz\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mW_hz\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mb_z\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mthree\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# 更新门参数\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     10\u001B[0m     \u001B[0mW_xr\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mW_hr\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mb_r\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mthree\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# 重置门参数\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     11\u001B[0m     \u001B[0mW_xh\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mW_hh\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mb_h\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mthree\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# 候选隐状态参数\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_18376/3769477392.py\u001B[0m in \u001B[0;36mthree\u001B[1;34m()\u001B[0m\n\u001B[0;32m      4\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrandn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msize\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m*\u001B[0m\u001B[1;36m0.01\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mthree\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 6\u001B[1;33m         return (normal((num_inputs, num_hiddens)),\n\u001B[0m\u001B[0;32m      7\u001B[0m                 \u001B[0mnormal\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnum_hiddens\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnum_hiddens\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      8\u001B[0m                 torch.zeros(num_hiddens, device=device))\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_18376/3769477392.py\u001B[0m in \u001B[0;36mnormal\u001B[1;34m(shape)\u001B[0m\n\u001B[0;32m      2\u001B[0m     \u001B[0mnum_inputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnum_outputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mvocab_size\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mnormal\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 4\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrandn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msize\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m*\u001B[0m\u001B[1;36m0.01\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      5\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mthree\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m         return (normal((num_inputs, num_hiddens)),\n",
      "\u001B[1;31mRuntimeError\u001B[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "vocab_size, num_hiddens, device = len(vocab), 256, d2l.try_gpu()\n",
    "num_epochs, lr = 500, 1\n",
    "model = d2l.RNNModelScratch(len(vocab), num_hiddens, device, get_params,\n",
    "                            init_gru_state, gru)\n",
    "d2l.train_ch8(model, train_iter, vocab, lr, num_epochs, device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 9.1.3. 简洁实现\n",
    "高级API包含了前文介绍的所有配置细节， 所以我们可以直接实例化门控循环单元模型。 这段代码的运行速度要快得多， 因为它使用的是编译好的运算符而不是Python来处理之前阐述的许多细节。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "28"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_inputs = vocab_size\n",
    "num_inputs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cuDNN error: CUDNN_STATUS_INTERNAL_ERROR",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_18376/2456613713.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[0mgru_layer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mGRU\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnum_inputs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mnum_hiddens\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0mmodel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0md2l\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mRNNModel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mgru_layer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvocab\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[0mmodel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      4\u001B[0m \u001B[0md2l\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain_ch8\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrain_iter\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvocab\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlr\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnum_epochs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\miniconda\\envs\\py385\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36mto\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    897\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0mt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mis_floating_point\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0mt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mis_complex\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32melse\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_blocking\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    898\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 899\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_apply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mconvert\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    900\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    901\u001B[0m     def register_backward_hook(\n",
      "\u001B[1;32mD:\\miniconda\\envs\\py385\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_apply\u001B[1;34m(self, fn)\u001B[0m\n\u001B[0;32m    568\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_apply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfn\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    569\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mchildren\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 570\u001B[1;33m             \u001B[0mmodule\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_apply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfn\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    571\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    572\u001B[0m         \u001B[1;32mdef\u001B[0m \u001B[0mcompute_should_use_set_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtensor\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtensor_applied\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\miniconda\\envs\\py385\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001B[0m in \u001B[0;36m_apply\u001B[1;34m(self, fn)\u001B[0m\n\u001B[0;32m    187\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_flat_weights\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;32mlambda\u001B[0m \u001B[0mwn\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mwn\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0mhasattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mwn\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32melse\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mwn\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mwn\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_flat_weights_names\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    188\u001B[0m         \u001B[1;31m# Flattens params (on CUDA)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 189\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mflatten_parameters\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    190\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    191\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mret\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\miniconda\\envs\\py385\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001B[0m in \u001B[0;36mflatten_parameters\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    173\u001B[0m                     \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mproj_size\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    174\u001B[0m                         \u001B[0mnum_weights\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 175\u001B[1;33m                     torch._cudnn_rnn_flatten_weight(\n\u001B[0m\u001B[0;32m    176\u001B[0m                         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_flat_weights\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnum_weights\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    177\u001B[0m                         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0minput_size\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrnn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_cudnn_mode\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmode\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: cuDNN error: CUDNN_STATUS_INTERNAL_ERROR"
     ]
    }
   ],
   "source": [
    "gru_layer = nn.GRU(num_inputs,num_hiddens)\n",
    "model = d2l.RNNModel(gru_layer, len(vocab))\n",
    "model = model.to(device=device)\n",
    "d2l.train_ch8(model, train_iter, vocab, lr, num_epochs, device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}