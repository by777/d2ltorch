{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "通常我们在处理图像时，我们希望逐渐降低隐藏表示的空间分辨率、聚集信息，\n",
    "这样随着我们在神经网络中层叠的上升，每个神经元对其敏感的感受野输入就越大。\n",
    "\n",
    "而我们的机器学习任务通常会跟全局图像的问题相关。（例如，“图像是否包含一只猫呢？”）\n",
    "\n",
    "##### 所以我们最后一层的神经元应该对整个输入的全局敏感\n",
    "通过逐渐聚合信息，生成越来越粗糙的映射，最终实现学习全局表示的目标，同时将卷积图层的所有优势保留在中间层。\n",
    "此外，当检测较底层的特征时（例如 6.2节中所讨论的边缘），我们通常希望这些特征保持某种程度上的平移不变性。例如，如果我们拍摄黑白之间轮廓清晰的图像X，并将整个图像向右移动一个像素，即Z[i, j] = X[i, j + 1]，则新图像Z的输出可能大不相同。而在现实中，随着拍摄角度的移动，任何物体几乎不可能发生在同一像素上。即使用三脚架拍摄一个静止的物体，由于快门的移动而引起的相机振动，可能会使所有物体左右移动一个像素（除了高端相机配备了特殊功能来解决这个问题）。\n",
    "\n",
    "本节将介绍汇聚（pooling）层，它具有双重目的：\n",
    "+ 降低卷积层对位置的敏感性\n",
    "+ 降低对空间降采样表示的敏感性"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6.5.1. 最大汇聚层和平均汇聚层\n",
    "在下面的代码中的pool2d函数，我们实现汇聚层的前向传播。 此功能类似于 6.2节中的corr2d函数。 然而，这里我们没有卷积核，输出为输入中每个区域的最大值或平均值。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def pool2d(X, pool_size, mode='max'):\n",
    "    p_h, p_w = pool_size\n",
    "    Y = torch.zeros((X.shape[0] - p_h + 1, X.shape[1] - p_w + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            if mode == 'max':\n",
    "                Y[i, j] = X[i : i + p_h, j : j + p_w].max()\n",
    "            elif mode == 'avg':\n",
    "                Y[i, j] = X[i : i + p_h, j : j + p_w].mean()\n",
    "    return Y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0., 1., 2.],\n        [3., 4., 5.],\n        [6., 7., 8.]])"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])\n",
    "X"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[2., 3.],\n        [5., 6.]])"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d(X, pool_size=(2,2), mode='avg')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[4., 5.],\n        [7., 8.]])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d(X, pool_size=(2,2), mode='max')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6.5.2. 填充和步幅\n",
    "与卷积层一样，汇聚层也可以改变输出形状。和以前一样，我们可以通过填充和步幅以获得所需的输出形状。 下面，我们用深度学习框架中内置的二维最大汇聚层，来演示汇聚层中填充和步幅的使用。 我们首先构造了一个输入张量X，它有四个维度，其中样本数和通道数都是1。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[[ 0.,  1.,  2.,  3.],\n          [ 4.,  5.,  6.,  7.],\n          [ 8.,  9., 10., 11.],\n          [12., 13., 14., 15.]]]])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(16, dtype=torch.float32).reshape((1,1,4,4))\n",
    "X"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "默认情况下，深度学习框架中的\n",
    "##### 步幅与汇聚窗口pool的大小相同，也就是说，如果我们使用形状为(3, 3)的pool，那么步幅也是(3, 3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[[10.]]]])"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d = nn.MaxPool2d(3)\n",
    "pool2d(X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "填充和步幅可以手动设定。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[[ 5.,  7.],\n          [13., 15.]]]])"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d = nn.MaxPool2d(3, padding=1, stride=2)\n",
    "pool2d(X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "当然，我们可以设定一个任意大小的矩形汇聚窗口，并分别设定填充和步幅的高度和宽度。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[[ 5.,  7.],\n          [13., 15.]]]])"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d = nn.MaxPool2d((2, 3), stride=(2, 3), padding=(0, 1))\n",
    "pool2d(X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6.5.3. 多个通道\n",
    "在处理多通道输入数据时，汇聚层再每个输入通道上单独运算。\n",
    "而不是像卷积一样再通道上对输入汇总。\n",
    "这意味着汇聚成的输出通道数与输入通道数相同"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[[[ 0.,  1.,  2.,  3.],\n           [ 4.,  5.,  6.,  7.],\n           [ 8.,  9., 10., 11.],\n           [12., 13., 14., 15.]],\n \n          [[ 1.,  2.,  3.,  4.],\n           [ 5.,  6.,  7.,  8.],\n           [ 9., 10., 11., 12.],\n           [13., 14., 15., 16.]]]]),\n tensor([[[[ 1.,  2.,  3.,  4.],\n           [ 5.,  6.,  7.,  8.],\n           [ 9., 10., 11., 12.],\n           [13., 14., 15., 16.]],\n \n          [[ 2.,  3.,  4.,  5.],\n           [ 6.,  7.,  8.,  9.],\n           [10., 11., 12., 13.],\n           [14., 15., 16., 17.]]]]))"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, X + 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[[ 0.,  1.,  2.,  3.],\n          [ 4.,  5.,  6.,  7.],\n          [ 8.,  9., 10., 11.],\n          [12., 13., 14., 15.]],\n\n         [[ 1.,  2.,  3.,  4.],\n          [ 5.,  6.,  7.,  8.],\n          [ 9., 10., 11., 12.],\n          [13., 14., 15., 16.]],\n\n         [[ 1.,  2.,  3.,  4.],\n          [ 5.,  6.,  7.,  8.],\n          [ 9., 10., 11., 12.],\n          [13., 14., 15., 16.]],\n\n         [[ 2.,  3.,  4.,  5.],\n          [ 6.,  7.,  8.,  9.],\n          [10., 11., 12., 13.],\n          [14., 15., 16., 17.]],\n\n         [[ 1.,  2.,  3.,  4.],\n          [ 5.,  6.,  7.,  8.],\n          [ 9., 10., 11., 12.],\n          [13., 14., 15., 16.]],\n\n         [[ 2.,  3.,  4.,  5.],\n          [ 6.,  7.,  8.,  9.],\n          [10., 11., 12., 13.],\n          [14., 15., 16., 17.]],\n\n         [[ 2.,  3.,  4.,  5.],\n          [ 6.,  7.,  8.,  9.],\n          [10., 11., 12., 13.],\n          [14., 15., 16., 17.]],\n\n         [[ 3.,  4.,  5.,  6.],\n          [ 7.,  8.,  9., 10.],\n          [11., 12., 13., 14.],\n          [15., 16., 17., 18.]]],\n\n\n        [[[ 1.,  2.,  3.,  4.],\n          [ 5.,  6.,  7.,  8.],\n          [ 9., 10., 11., 12.],\n          [13., 14., 15., 16.]],\n\n         [[ 2.,  3.,  4.,  5.],\n          [ 6.,  7.,  8.,  9.],\n          [10., 11., 12., 13.],\n          [14., 15., 16., 17.]],\n\n         [[ 2.,  3.,  4.,  5.],\n          [ 6.,  7.,  8.,  9.],\n          [10., 11., 12., 13.],\n          [14., 15., 16., 17.]],\n\n         [[ 3.,  4.,  5.,  6.],\n          [ 7.,  8.,  9., 10.],\n          [11., 12., 13., 14.],\n          [15., 16., 17., 18.]],\n\n         [[ 2.,  3.,  4.,  5.],\n          [ 6.,  7.,  8.,  9.],\n          [10., 11., 12., 13.],\n          [14., 15., 16., 17.]],\n\n         [[ 3.,  4.,  5.,  6.],\n          [ 7.,  8.,  9., 10.],\n          [11., 12., 13., 14.],\n          [15., 16., 17., 18.]],\n\n         [[ 3.,  4.,  5.,  6.],\n          [ 7.,  8.,  9., 10.],\n          [11., 12., 13., 14.],\n          [15., 16., 17., 18.]],\n\n         [[ 4.,  5.,  6.,  7.],\n          [ 8.,  9., 10., 11.],\n          [12., 13., 14., 15.],\n          [16., 17., 18., 19.]]],\n\n\n        [[[ 1.,  2.,  3.,  4.],\n          [ 5.,  6.,  7.,  8.],\n          [ 9., 10., 11., 12.],\n          [13., 14., 15., 16.]],\n\n         [[ 2.,  3.,  4.,  5.],\n          [ 6.,  7.,  8.,  9.],\n          [10., 11., 12., 13.],\n          [14., 15., 16., 17.]],\n\n         [[ 2.,  3.,  4.,  5.],\n          [ 6.,  7.,  8.,  9.],\n          [10., 11., 12., 13.],\n          [14., 15., 16., 17.]],\n\n         [[ 3.,  4.,  5.,  6.],\n          [ 7.,  8.,  9., 10.],\n          [11., 12., 13., 14.],\n          [15., 16., 17., 18.]],\n\n         [[ 2.,  3.,  4.,  5.],\n          [ 6.,  7.,  8.,  9.],\n          [10., 11., 12., 13.],\n          [14., 15., 16., 17.]],\n\n         [[ 3.,  4.,  5.,  6.],\n          [ 7.,  8.,  9., 10.],\n          [11., 12., 13., 14.],\n          [15., 16., 17., 18.]],\n\n         [[ 3.,  4.,  5.,  6.],\n          [ 7.,  8.,  9., 10.],\n          [11., 12., 13., 14.],\n          [15., 16., 17., 18.]],\n\n         [[ 4.,  5.,  6.,  7.],\n          [ 8.,  9., 10., 11.],\n          [12., 13., 14., 15.],\n          [16., 17., 18., 19.]]],\n\n\n        [[[ 2.,  3.,  4.,  5.],\n          [ 6.,  7.,  8.,  9.],\n          [10., 11., 12., 13.],\n          [14., 15., 16., 17.]],\n\n         [[ 3.,  4.,  5.,  6.],\n          [ 7.,  8.,  9., 10.],\n          [11., 12., 13., 14.],\n          [15., 16., 17., 18.]],\n\n         [[ 3.,  4.,  5.,  6.],\n          [ 7.,  8.,  9., 10.],\n          [11., 12., 13., 14.],\n          [15., 16., 17., 18.]],\n\n         [[ 4.,  5.,  6.,  7.],\n          [ 8.,  9., 10., 11.],\n          [12., 13., 14., 15.],\n          [16., 17., 18., 19.]],\n\n         [[ 3.,  4.,  5.,  6.],\n          [ 7.,  8.,  9., 10.],\n          [11., 12., 13., 14.],\n          [15., 16., 17., 18.]],\n\n         [[ 4.,  5.,  6.,  7.],\n          [ 8.,  9., 10., 11.],\n          [12., 13., 14., 15.],\n          [16., 17., 18., 19.]],\n\n         [[ 4.,  5.,  6.,  7.],\n          [ 8.,  9., 10., 11.],\n          [12., 13., 14., 15.],\n          [16., 17., 18., 19.]],\n\n         [[ 5.,  6.,  7.,  8.],\n          [ 9., 10., 11., 12.],\n          [13., 14., 15., 16.],\n          [17., 18., 19., 20.]]]])"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.cat((X, X+1),1)\n",
    "X"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "如下所示，汇聚后输出通道的数量仍然是2。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[[ 5.,  7.],\n          [13., 15.]],\n\n         [[ 6.,  8.],\n          [14., 16.]],\n\n         [[ 6.,  8.],\n          [14., 16.]],\n\n         [[ 7.,  9.],\n          [15., 17.]],\n\n         [[ 6.,  8.],\n          [14., 16.]],\n\n         [[ 7.,  9.],\n          [15., 17.]],\n\n         [[ 7.,  9.],\n          [15., 17.]],\n\n         [[ 8., 10.],\n          [16., 18.]]],\n\n\n        [[[ 6.,  8.],\n          [14., 16.]],\n\n         [[ 7.,  9.],\n          [15., 17.]],\n\n         [[ 7.,  9.],\n          [15., 17.]],\n\n         [[ 8., 10.],\n          [16., 18.]],\n\n         [[ 7.,  9.],\n          [15., 17.]],\n\n         [[ 8., 10.],\n          [16., 18.]],\n\n         [[ 8., 10.],\n          [16., 18.]],\n\n         [[ 9., 11.],\n          [17., 19.]]],\n\n\n        [[[ 6.,  8.],\n          [14., 16.]],\n\n         [[ 7.,  9.],\n          [15., 17.]],\n\n         [[ 7.,  9.],\n          [15., 17.]],\n\n         [[ 8., 10.],\n          [16., 18.]],\n\n         [[ 7.,  9.],\n          [15., 17.]],\n\n         [[ 8., 10.],\n          [16., 18.]],\n\n         [[ 8., 10.],\n          [16., 18.]],\n\n         [[ 9., 11.],\n          [17., 19.]]],\n\n\n        [[[ 7.,  9.],\n          [15., 17.]],\n\n         [[ 8., 10.],\n          [16., 18.]],\n\n         [[ 8., 10.],\n          [16., 18.]],\n\n         [[ 9., 11.],\n          [17., 19.]],\n\n         [[ 8., 10.],\n          [16., 18.]],\n\n         [[ 9., 11.],\n          [17., 19.]],\n\n         [[ 9., 11.],\n          [17., 19.]],\n\n         [[10., 12.],\n          [18., 20.]]]])"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d = nn.MaxPool2d(3, padding=1, stride=2)\n",
    "pool2d(X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6.5.4. 小结\n",
    "...\n",
    "...\n",
    "使用汇聚层以及大于1的步幅，可以减少 ***空间维度（如高度与宽度）***\n",
    "..."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}